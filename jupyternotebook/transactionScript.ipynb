{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dependencies\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getDataFrameFromFiles - use pandas to read the csv file and get a dataframe to work with it\n",
    "# @params: path - the path of the data file\n",
    "# @return: dataframe created from the file\n",
    "##\n",
    "def getDataFrameFromFile(path):\n",
    "    #Use index_col so pandas doesn't use the fisrt column as an index column.\n",
    "    return pd.read_csv(path, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sortDataFrame - Sorts dataframe by column and ascending or descending order\n",
    "# @params: dataframe - dataframe that will be sorted\n",
    "#          column - name of column\n",
    "#          ascending - True for ascending sort. False for descending sort.\n",
    "# @return: sortedDF - the dataframe sorted\n",
    "##\n",
    "def sortDataFrame(dataframe, column, ascending):\n",
    "    sortedDF = dataframe.sort_values(by=[column], ascending=ascending)\n",
    "\n",
    "    #Reset the index of the dataframe\n",
    "    sortedDF.index = [x for x in range(0, len(sortedDF))]\n",
    "    return sortedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insertEmptyRow - Inserts an empty row in a dataframe on the index defined.\n",
    "# @params: dataframe - the dataframe in which the empty row will be inserted.\n",
    "#          index - index where the row will be inserted. Index starts with number for first element of the dataframe.\n",
    "# @return: df - dataframe with the new empty row inserted.\n",
    "##\n",
    "def insertEmptyRow(dataframe, index):\n",
    "    row = pd.DataFrame(emptyDict, index=[index])\n",
    "    df = pd.concat([dataframe.iloc[:index - 1], row, dataframe.iloc[index - 1:]], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compareRowData - checks if the data of two rows is the same or not\n",
    "# @params: clientRow - first pandas.Series to be compared\n",
    "#          tutukaRow - pandas.Series which will be compared against.\n",
    "# @return: Boolean\n",
    "##\n",
    "def compareRowData(clientRow, tutukaRow):\n",
    "    flag = True\n",
    "    for x in range(0,len(clientRow)):\n",
    "        if(not (clientRow[x] == tutukaRow[x])):\n",
    "            flag = False\n",
    "            break\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getMaxSize - return the len of the biggest dataframe\n",
    "# @params - none\n",
    "# @return - length\n",
    "##\n",
    "def getMaxSize():\n",
    "    #Get the length of both files so we can choose the largest file and iterate over that one\n",
    "    clientLen = len(sortedClient)\n",
    "    tutukaLen = len(sortedTutuka)\n",
    "\n",
    "    #Assign the biggest length\n",
    "    dfLen = clientLen if (clientLen > tutukaLen) else tutukaLen\n",
    "    return dfLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv files path\n",
    "clientFilePath = os.path.join(\"..\", \"Resources\", \"ClientMarkoffFile20140113.csv\")\n",
    "tutukaFilePath = os.path.join(\"..\", \"Resources\", \"TutukaMarkoffFile20140113.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframes for each file\n",
    "client_df = getDataFrameFromFile(clientFilePath)\n",
    "tutuka_df = getDataFrameFromFile(tutukaFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emptyDict stores in a dictionary all the column names of a dataframe as keys and empty values.\n",
    "#This variable helps out in the process of creating an empty row using the insertEmptyRow declared before.\n",
    "emptyDict = {}\n",
    "for column in client_df.columns:\n",
    "    emptyDict[column] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Sort client dataframe by TransactionID (ascending order) so its easier to find possible matches.\n",
    "sortedClient = sortDataFrame(client_df, \"TransactionID\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort tutuka dataframe by TransactionID (ascending order)\n",
    "sortedTutuka = sortDataFrame(tutuka_df, \"TransactionID\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We look through each dataframe and search if there are transactions that are the same.\n",
    "#If we find the same transaction in the same dataframe. We drop it.\n",
    "#Because is a transaction that is repeated and will cause problems. i.e. calculating the correct total amount the client\n",
    "#or a reatil store really  sold.\n",
    "\n",
    "#Drop duplicates in sortedClient dataframe\n",
    "sortedClient.drop_duplicates(inplace=True)\n",
    "#Reset the index of the dataframe\n",
    "sortedClient.index = [x for x in range(0, len(sortedClient))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates in sortedTutuka dataframe\n",
    "sortedTutuka.drop_duplicates(inplace=True)\n",
    "#Reset the index of the dataframe\n",
    "sortedTutuka.index = [x for x in range(0, len(sortedTutuka))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Client file matches: 288\nClient file possible: 10\nClient file Mismatches: 6\nTutuka file matches: 288\nTutuka file possible: 10\nTutuka file Mismatches: 6\n"
    }
   ],
   "source": [
    "# We start the iteration through the dataframes comparing each index within both dataframes. This is possible because we have sorted the data\n",
    "# And We dropped duplicates too\n",
    "index = 0\n",
    "clientMatch = 0\n",
    "clientMismatch = 0\n",
    "clientPossible = 0\n",
    "tutukaMatch = 0\n",
    "tutukaMismatch = 0\n",
    "tutukaPossible = 0\n",
    "#We use the biggest dataframe size to iterate in the while loop\n",
    "maxIndex = getMaxSize()\n",
    "\n",
    "while(index < maxIndex):\n",
    "    try:\n",
    "        clientRow = sortedClient.iloc[index]\n",
    "        tutukaRow = sortedTutuka.iloc[index]\n",
    "\n",
    "        #First only check if the TransactionsID are the same. If both match, continue to check all the other data.\n",
    "        if(clientRow[\"TransactionID\"] == tutukaRow[\"TransactionID\"]):\n",
    "            if(compareRowData(clientRow, tutukaRow)): \n",
    "                #Add one match to each file because the transaction is on both. So is a perfect match for both of them\n",
    "                clientMatch += 1\n",
    "                tutukaMatch += 1\n",
    "            else:\n",
    "                #If they have the same ID but different information it may be possible that script has switched the transactionDescription in one file.\n",
    "                #But the transaction may still have a match\n",
    "                #So we check with the next row if we find the same description.\n",
    "\n",
    "                tutukaNextRow = sortedTutuka.iloc[index + 1]\n",
    "                clientNextRow = sortedClient.iloc[index + 1]\n",
    "                if(compareRowData(clientRow, tutukaNextRow)):\n",
    "                    \n",
    "                    #Add new matches\n",
    "                    clientMatch += 1\n",
    "                    tutukaMatch += 1\n",
    "                    if(compareRowData(clientNextRow, tutukaRow)):\n",
    "                        clientMatch += 1\n",
    "                        tutukaMatch += 1\n",
    "                    else:\n",
    "                        clientMismatch += 1\n",
    "                        tutukaMismatch += 1\n",
    "                    #Add one to index because we already checked the next row\n",
    "                    index += 1\n",
    "                else:\n",
    "                    #Here it means transactions have the same ID but have at least one column different so they are a possible match.\n",
    "                    clientPossible += 1\n",
    "                    tutukaPossible += 1              \n",
    "        else:\n",
    "            #The ID's are not the same so we will check which ID is bigger. The biggest ID will have an empty row inserted before him.\n",
    "            #With this method we ensure we check for same ID's even if they are in different dataframe index.\n",
    "\n",
    "            if(clientRow[\"TransactionID\"] > tutukaRow[\"TransactionID\"]):\n",
    "                #If client id is bigger than tutuka ID it means we insert new row to client and the Tutuka ID doesn't have a match.\n",
    "                sortedClient = insertEmptyRow(sortedClient, index + 1)\n",
    "\n",
    "                #Each time we add a row to a dataframe we update the index to keep looping through all the dataframes rows\n",
    "                maxIndex = getMaxSize()\n",
    "                tutukaMismatch += 1\n",
    "                \n",
    "            else:\n",
    "                #Viceversa tutuka ID is bigger than client ID it means we insert new row to tutuka and the client ID doesn't have a match.\n",
    "                sortedTutuka = insertEmptyRow(sortedTutuka, index + 1)\n",
    "\n",
    "                #Each time we add a row to a dataframe we update the index to keep looping through all the dataframes rows\n",
    "                maxIndex = getMaxSize()\n",
    "                clientMismatch += 1\n",
    "\n",
    "        index += 1\n",
    "    except (IndexError):\n",
    "        #Catching this exception means one dataframe has more rows than the other one. We have reached the end of one dataframe.\n",
    "        #Break the loop\n",
    "        break\n",
    "\n",
    "#After exiting the loop we check until which index we reached. And if a dataframe length is bigger than the last index we check.\n",
    "#It means that dataframe has more transactions that don't have a match.\n",
    "\n",
    "clientLen = len(sortedClient)\n",
    "tutukaLen = len(sortedTutuka)\n",
    "\n",
    "if(index < maxIndex):\n",
    "    if(clientLen > index):\n",
    "        #Client length is bigger than index so it has clientLen - index mismatched transactions to add.\n",
    "        clientMismatch = clientMismatch + (clientLen - index)\n",
    "    else:\n",
    "        #Tutuka length is bigger than index so it has tutukaLen - index mismatched transactions to add.\n",
    "        tutukaMismatch = tutukaMismatch + (tutukaLen - index)\n",
    "\n",
    "    \n",
    "print(f'Client file matches: {clientMatch}')\n",
    "print(f'Client file possible: {clientPossible}')\n",
    "print(f'Client file Mismatches: {clientMismatch}')\n",
    "print(f'Tutuka file matches: {tutukaMatch}')\n",
    "print(f'Tutuka file possible: {tutukaPossible}')\n",
    "print(f'Tutuka file Mismatches: {tutukaMismatch}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}